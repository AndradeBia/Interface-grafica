
````markdown
# HEVA: Pipeline Integrado para An√°lise de Les√µes de Pele üî¨

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

Bem-vindo ao reposit√≥rio do **HEVA** (Hybrid Ensemble for Vision Analysis), um projeto que implementa uma interface gr√°fica para um robusto pipeline de machine learning de duas etapas para a classifica√ß√£o de les√µes de pele.

A aplica√ß√£o, constru√≠da com **Gradio**, permite que o usu√°rio fa√ßa o upload de uma imagem de qualquer tamanho. A imagem ent√£o passa por:
1.  Um modelo de **segmenta√ß√£o sem√¢ntica (Segformer)** para identificar e isolar a les√£o.
2.  Um poderoso **modelo de classifica√ß√£o em ensemble** que combina descritores de textura, features da ResNet e do Vision Transformer (ViT) para classificar a les√£o como "Benigna" ou "Maligna".



## ‚ú® Principais Funcionalidades

-   **Interface Amig√°vel:** Interface web simples e intuitiva criada com Gradio.
-   **Pipeline de Duas Etapas:** Primeiro segmenta, depois classifica, imitando o foco de um especialista.
-   **Modelo Ensemble H√≠brido:** Combina a for√ßa dos descritores cl√°ssicos (LBP) com o poder de representa√ß√£o de modelos de deep learning (ResNet e ViT).
-   **Flexibilidade de Entrada:** Aceita imagens de les√µes de pele de diferentes tamanhos e resolu√ß√µes.
-   **Feedback Visual:** Al√©m da classifica√ß√£o, a interface exibe a m√°scara de segmenta√ß√£o gerada pelo modelo, mostrando qual √°rea da imagem foi analisada.

## üèóÔ∏è Arquitetura do Modelo

O pipeline do HEVA √© dividido em duas etapas principais:

### Etapa 1: Segmenta√ß√£o Sem√¢ntica com Segformer

Qualquer imagem de entrada √© primeiramente processada por um modelo **Segformer** (especificamente, `nvidia/segformer-b5-finetuned-ade-640-640`) que foi afinado para identificar les√µes de pele. O resultado √© uma m√°scara bin√°ria que isola a regi√£o de interesse.

### Etapa 2: Classifica√ß√£o com Ensemble H√≠brido

Ap√≥s o isolamento da les√£o, a √°rea √© recortada e pr√©-processada. Em seguida, extra√≠mos tr√™s conjuntos de caracter√≠sticas distintas:

1.  **Descritores de Textura:** Atrav√©s do **Local Binary Pattern (LBP)**, capturamos caracter√≠sticas de textura da superf√≠cie da les√£o.
2.  **Features da ResNet50:** Utilizamos uma **ResNet50** pr√©-treinada para extrair features hier√°rquicas da imagem.
3.  **Features do Vision Transformer (ViT):** Usamos um **ViT** (`google/vit-base-patch16-224-in21k`) para capturar rela√ß√µes globais e contextuais na imagem da les√£o.

Finalmente, essas tr√™s fontes de informa√ß√£o s√£o concatenadas e alimentam um classificador **Support Vector Machine (SVM)**, que realiza o diagn√≥stico final.

## üöÄ Instala√ß√£o e Execu√ß√£o

Para executar esta aplica√ß√£o localmente, siga os passos abaixo.

### Pr√©-requisitos

-   Python 3.8+
-   Git
-   **Git LFS** (Large File Storage)

### 1. Instala√ß√£o do Git LFS

Este reposit√≥rio utiliza o Git LFS para gerenciar os arquivos grandes dos modelos. **√â crucial que voc√™ instale o Git LFS** no seu computador antes de clonar o reposit√≥rio.

-   Visite [git-lfs.github.com](https://git-lfs.github.com) e siga as instru√ß√µes de download e instala√ß√£o para o seu sistema operacional.
-   Ap√≥s a instala√ß√£o, configure o Git LFS executando o seguinte comando no seu terminal:
    ```bash
    git lfs install
    ```

### 2. Clonando o Reposit√≥rio

Com o Git LFS instalado, clone o reposit√≥rio. Os arquivos grandes dos modelos ser√£o baixados automaticamente durante o processo de `clone`.

```bash
git clone [https://github.com/AndradeBia/Interface-grafica.git](https://github.com/AndradeBia/Interface-grafica.git)
cd Interface-grafica
```
*Se os arquivos dos modelos n√£o forem baixados (e aparecerem como pequenos arquivos de texto), execute `git lfs pull` dentro da pasta do projeto.*

### 3. Configurando o Ambiente Virtual

√â uma boa pr√°tica criar um ambiente virtual para isolar as depend√™ncias do projeto.

```bash
# Criar um ambiente virtual
python -m venv venv

# Ativar o ambiente (Windows)
.\venv\Scripts\activate

# Ativar o ambiente (macOS/Linux)
source venv/bin/activate
```

### 4. Instalando as Depend√™ncias

Instale todas as bibliotecas necess√°rias com um √∫nico comando:

```bash
pip install -r requirements.txt
```

### 5. Executando a Aplica√ß√£o

Com tudo instalado, inicie a interface Gradio:

```bash
python app.py
```
Aguarde a mensagem "üß† Carregando todos os modelos...", que pode levar alguns instantes. Ap√≥s o carregamento, acesse o endere√ßo local (geralmente `http://127.0.0.1:7860`) que aparecer√° no seu terminal.

## üìÅ Estrutura dos Arquivos

```
‚îî‚îÄ‚îÄ andradebia-interface-grafica/
    ‚îú‚îÄ‚îÄ app.py                      # C√≥digo principal da aplica√ß√£o Gradio e do pipeline.
    ‚îú‚îÄ‚îÄ requirements.txt            # Lista de depend√™ncias Python.
    ‚îú‚îÄ‚îÄ feature_extractor_finetuned.h5 # Modelo ResNet50 para extra√ß√£o de features.
    ‚îú‚îÄ‚îÄ segformer_best_model.pth    # Pesos do modelo Segformer afinado.
    ‚îú‚îÄ‚îÄ svm_pipeline_artifacts.pkl  # Artefatos do SVM (modelo, scaler, etc.).
    ‚îî‚îÄ‚îÄ vit_model/                    # Pasta contendo o modelo ViT.
        ‚îú‚îÄ‚îÄ config.json
        ‚îî‚îÄ‚îÄ model.safetensors
```

## üìÑ Licen√ßa

Este projeto est√° licenciado sob a Licen√ßa MIT. Veja o arquivo `LICENSE` para mais detalhes.
````
